{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hmmlearn\n",
      "  Downloading hmmlearn-0.2.3-cp37-cp37m-win_amd64.whl (111 kB)\n",
      "Requirement already satisfied: scipy>=0.15 in c:\\programdata\\anaconda3\\envs\\voice\\lib\\site-packages (from hmmlearn) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.16 in c:\\programdata\\anaconda3\\envs\\voice\\lib\\site-packages (from hmmlearn) (0.22.2.post1)\n",
      "Requirement already satisfied: numpy>=1.10 in c:\\programdata\\anaconda3\\envs\\voice\\lib\\site-packages (from hmmlearn) (1.15.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\envs\\voice\\lib\\site-packages (from scikit-learn>=0.16->hmmlearn) (0.14.1)\n",
      "Installing collected packages: hmmlearn\n",
      "Successfully installed hmmlearn-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "#     print(files)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    return mfcc\n",
    "\n",
    "def clustering(X, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    #print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "    return kmeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\voice\\lib\\site-packages\\scipy\\signal\\_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors (10116, 36)\n",
      "centers (10, 36)\n",
      "training la\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -5038.7426             +nan\n",
      "         2       -4278.9012        +759.8414\n",
      "         3       -4260.7182         +18.1830\n",
      "         4       -4225.5719         +35.1463\n",
      "         5       -4140.6516         +84.9203\n",
      "         6       -3965.2941        +175.3575\n",
      "         7       -3743.9959        +221.2981\n",
      "         8       -3579.5375        +164.4585\n",
      "         9       -3504.6529         +74.8846\n",
      "        10       -3463.3442         +41.3086\n",
      "        11       -3420.1750         +43.1692\n",
      "        12       -3361.1926         +58.9824\n",
      "        13       -3272.3269         +88.8657\n",
      "        14       -3168.0716        +104.2553\n",
      "        15       -3093.0531         +75.0185\n",
      "        16       -3022.7719         +70.2811\n",
      "        17       -2909.8869        +112.8851\n",
      "        18       -2753.4780        +156.4089\n",
      "        19       -2695.6743         +57.8037\n",
      "        20       -2672.4253         +23.2490\n",
      "        21       -2655.4133         +17.0119\n",
      "        22       -2644.9840         +10.4294\n",
      "        23       -2637.7668          +7.2172\n",
      "        24       -2632.9940          +4.7728\n",
      "        25       -2629.1070          +3.8870\n",
      "        26       -2624.8065          +4.3005\n",
      "        27       -2619.4988          +5.3078\n",
      "        28       -2613.4571          +6.0417\n",
      "        29       -2607.9217          +5.5354\n",
      "        30       -2604.0305          +3.8912\n",
      "        31       -2601.8342          +2.1963\n",
      "        32       -2600.7418          +1.0924\n",
      "        33       -2600.2115          +0.5303\n",
      "        34       -2599.9360          +0.2755\n",
      "        35       -2599.7411          +0.1948\n",
      "        36       -2599.2668          +0.4743\n",
      "        37       -2597.8604          +1.4064\n",
      "        38       -2596.8811          +0.9793\n",
      "        39       -2596.4233          +0.4578\n",
      "        40       -2596.1324          +0.2909\n",
      "        41       -2595.9391          +0.1933\n",
      "        42       -2595.8073          +0.1318\n",
      "        43       -2595.7156          +0.0917\n",
      "        44       -2595.6509          +0.0648\n",
      "        45       -2595.6045          +0.0463\n",
      "        46       -2595.5710          +0.0335\n",
      "        47       -2595.5463          +0.0247\n",
      "        48       -2595.5279          +0.0184\n",
      "        49       -2595.5139          +0.0140\n",
      "        50       -2595.5030          +0.0109\n",
      "        51       -2595.4944          +0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "la\n",
      "[[0.8  0.15 0.02 0.   0.02 0.  ]\n",
      " [0.19 0.56 0.   0.   0.24 0.01]\n",
      " [0.13 0.01 0.86 0.   0.   0.  ]\n",
      " [0.   0.   0.06 0.87 0.02 0.06]\n",
      " [0.01 0.15 0.   0.   0.71 0.13]\n",
      " [0.   0.03 0.   0.   0.1  0.86]]\n",
      "training cua\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -4122.8456             +nan\n",
      "         2       -2826.1033       +1296.7423\n",
      "         3       -2798.1131         +27.9902\n",
      "         4       -2734.3745         +63.7386\n",
      "         5       -2585.4608        +148.9138\n",
      "         6       -2378.2544        +207.2063\n",
      "         7       -2220.2307        +158.0238\n",
      "         8       -2113.6716        +106.5591\n",
      "         9       -2037.6976         +75.9739\n",
      "        10       -1990.3369         +47.3607\n",
      "        11       -1956.6610         +33.6760\n",
      "        12       -1927.7119         +28.9490\n",
      "        13       -1900.2767         +27.4352\n",
      "        14       -1875.5789         +24.6979\n",
      "        15       -1856.2109         +19.3679\n",
      "        16       -1843.2063         +13.0046\n",
      "        17       -1834.3105          +8.8958\n",
      "        18       -1827.7943          +6.5162\n",
      "        19       -1822.8068          +4.9875\n",
      "        20       -1818.7324          +4.0744\n",
      "        21       -1815.1412          +3.5912\n",
      "        22       -1811.7808          +3.3604\n",
      "        23       -1808.4965          +3.2843\n",
      "        24       -1805.1771          +3.3194\n",
      "        25       -1801.7401          +3.4370\n",
      "        26       -1798.1547          +3.5854\n",
      "        27       -1794.4848          +3.6699\n",
      "        28       -1790.8939          +3.5909\n",
      "        29       -1787.5907          +3.3032\n",
      "        30       -1784.7618          +2.8289\n",
      "        31       -1782.5077          +2.2541\n",
      "        32       -1780.8114          +1.6964\n",
      "        33       -1779.5735          +1.2379\n",
      "        34       -1778.6717          +0.9017\n",
      "        35       -1778.0001          +0.6716\n",
      "        36       -1777.4816          +0.5185\n",
      "        37       -1777.0650          +0.4166\n",
      "        38       -1776.7175          +0.3475\n",
      "        39       -1776.4180          +0.2994\n",
      "        40       -1776.1532          +0.2649\n",
      "        41       -1775.9138          +0.2394\n",
      "        42       -1775.6936          +0.2201\n",
      "        43       -1775.4884          +0.2053\n",
      "        44       -1775.2947          +0.1936\n",
      "        45       -1775.1104          +0.1844\n",
      "        46       -1774.9333          +0.1771\n",
      "        47       -1774.7620          +0.1713\n",
      "        48       -1774.5951          +0.1669\n",
      "        49       -1774.4315          +0.1636\n",
      "        50       -1774.2703          +0.1612\n",
      "        51       -1774.1106          +0.1597\n",
      "        52       -1773.9515          +0.1591\n",
      "        53       -1773.7924          +0.1591\n",
      "        54       -1773.6324          +0.1599\n",
      "        55       -1773.4711          +0.1614\n",
      "        56       -1773.3075          +0.1635\n",
      "        57       -1773.1412          +0.1664\n",
      "        58       -1772.9713          +0.1699\n",
      "        59       -1772.7972          +0.1741\n",
      "        60       -1772.6181          +0.1791\n",
      "        61       -1772.4332          +0.1849\n",
      "        62       -1772.2416          +0.1915\n",
      "        63       -1772.0425          +0.1991\n",
      "        64       -1771.8350          +0.2075\n",
      "        65       -1771.6180          +0.2170\n",
      "        66       -1771.3906          +0.2274\n",
      "        67       -1771.1517          +0.2389\n",
      "        68       -1770.9002          +0.2515\n",
      "        69       -1770.6351          +0.2651\n",
      "        70       -1770.3554          +0.2798\n",
      "        71       -1770.0601          +0.2953\n",
      "        72       -1769.7486          +0.3115\n",
      "        73       -1769.4208          +0.3278\n",
      "        74       -1769.0775          +0.3433\n",
      "        75       -1768.7206          +0.3569\n",
      "        76       -1768.3541          +0.3666\n",
      "        77       -1767.9836          +0.3704\n",
      "        78       -1767.6171          +0.3665\n",
      "        79       -1767.2634          +0.3537\n",
      "        80       -1766.9312          +0.3322\n",
      "        81       -1766.6278          +0.3034\n",
      "        82       -1766.3578          +0.2700\n",
      "        83       -1766.1230          +0.2347\n",
      "        84       -1765.9228          +0.2002\n",
      "        85       -1765.7545          +0.1683\n",
      "        86       -1765.6143          +0.1401\n",
      "        87       -1765.4983          +0.1160\n",
      "        88       -1765.4024          +0.0959\n",
      "        89       -1765.3229          +0.0795\n",
      "        90       -1765.2567          +0.0662\n",
      "        91       -1765.2012          +0.0555\n",
      "        92       -1765.1542          +0.0470\n",
      "        93       -1765.1139          +0.0403\n",
      "        94       -1765.0790          +0.0349\n",
      "        95       -1765.0483          +0.0307\n",
      "        96       -1765.0210          +0.0274\n",
      "        97       -1764.9962          +0.0248\n",
      "        98       -1764.9734          +0.0228\n",
      "        99       -1764.9520          +0.0214\n",
      "       100       -1764.9316          +0.0204\n",
      "       101       -1764.9117          +0.0199\n",
      "       102       -1764.8918          +0.0199\n",
      "       103       -1764.8716          +0.0202\n",
      "       104       -1764.8505          +0.0211\n",
      "       105       -1764.8281          +0.0224\n",
      "       106       -1764.8039          +0.0242\n",
      "       107       -1764.7772          +0.0267\n",
      "       108       -1764.7474          +0.0298\n",
      "       109       -1764.7138          +0.0336\n",
      "       110       -1764.6755          +0.0383\n",
      "       111       -1764.6318          +0.0438\n",
      "       112       -1764.5816          +0.0502\n",
      "       113       -1764.5241          +0.0575\n",
      "       114       -1764.4584          +0.0657\n",
      "       115       -1764.3836          +0.0747\n",
      "       116       -1764.2993          +0.0843\n",
      "       117       -1764.2051          +0.0942\n",
      "       118       -1764.1011          +0.1040\n",
      "       119       -1763.9881          +0.1131\n",
      "       120       -1763.8672          +0.1209\n",
      "       121       -1763.7402          +0.1270\n",
      "       122       -1763.6094          +0.1308\n",
      "       123       -1763.4771          +0.1323\n",
      "       124       -1763.3456          +0.1314\n",
      "       125       -1763.2171          +0.1285\n",
      "       126       -1763.0931          +0.1240\n",
      "       127       -1762.9747          +0.1184\n",
      "       128       -1762.8624          +0.1123\n",
      "       129       -1762.7564          +0.1060\n",
      "       130       -1762.6567          +0.0998\n",
      "       131       -1762.5627          +0.0939\n",
      "       132       -1762.4743          +0.0885\n",
      "       133       -1762.3908          +0.0834\n",
      "       134       -1762.3121          +0.0788\n",
      "       135       -1762.2376          +0.0745\n",
      "       136       -1762.1671          +0.0705\n",
      "       137       -1762.1003          +0.0667\n",
      "       138       -1762.0372          +0.0632\n",
      "       139       -1761.9774          +0.0598\n",
      "       140       -1761.9208          +0.0565\n",
      "       141       -1761.8674          +0.0534\n",
      "       142       -1761.8170          +0.0504\n",
      "       143       -1761.7694          +0.0476\n",
      "       144       -1761.7246          +0.0448\n",
      "       145       -1761.6823          +0.0422\n",
      "       146       -1761.6426          +0.0397\n",
      "       147       -1761.6052          +0.0374\n",
      "       148       -1761.5700          +0.0352\n",
      "       149       -1761.5369          +0.0331\n",
      "       150       -1761.5058          +0.0311\n",
      "       151       -1761.4765          +0.0293\n",
      "       152       -1761.4489          +0.0276\n",
      "       153       -1761.4229          +0.0260\n",
      "       154       -1761.3984          +0.0245\n",
      "       155       -1761.3752          +0.0231\n",
      "       156       -1761.3534          +0.0218\n",
      "       157       -1761.3328          +0.0206\n",
      "       158       -1761.3133          +0.0195\n",
      "       159       -1761.2949          +0.0184\n",
      "       160       -1761.2774          +0.0174\n",
      "       161       -1761.2609          +0.0165\n",
      "       162       -1761.2453          +0.0156\n",
      "       163       -1761.2306          +0.0148\n",
      "       164       -1761.2165          +0.0140\n",
      "       165       -1761.2032          +0.0133\n",
      "       166       -1761.1906          +0.0126\n",
      "       167       -1761.1787          +0.0120\n",
      "       168       -1761.1673          +0.0114\n",
      "       169       -1761.1564          +0.0108\n",
      "       170       -1761.1461          +0.0103\n",
      "       171       -1761.1363          +0.0098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "cua\n",
      "[[0.63 0.   0.   0.03 0.02 0.   0.   0.21 0.11]\n",
      " [0.   0.7  0.   0.09 0.2  0.01 0.   0.   0.  ]\n",
      " [0.   0.   0.65 0.   0.   0.35 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.64 0.   0.   0.36 0.   0.  ]\n",
      " [0.   0.09 0.   0.03 0.75 0.03 0.1  0.   0.  ]\n",
      " [0.   0.   0.   0.   0.49 0.51 0.   0.   0.  ]\n",
      " [0.09 0.   0.   0.01 0.   0.   0.65 0.   0.25]\n",
      " [0.   0.   0.02 0.   0.   0.14 0.   0.72 0.11]\n",
      " [0.03 0.   0.09 0.   0.   0.22 0.   0.25 0.41]]\n",
      "training nguoi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -6387.8672             +nan\n",
      "         2       -5950.7771        +437.0900\n",
      "         3       -5904.5871         +46.1900\n",
      "         4       -5808.9559         +95.6312\n",
      "         5       -5611.2080        +197.7479\n",
      "         6       -5300.6550        +310.5531\n",
      "         7       -4900.0443        +400.6106\n",
      "         8       -4372.7501        +527.2943\n",
      "         9       -3932.8737        +439.8764\n",
      "        10       -3698.1304        +234.7433\n",
      "        11       -3585.6943        +112.4361\n",
      "        12       -3489.6279         +96.0664\n",
      "        13       -3413.5246         +76.1034\n",
      "        14       -3366.6473         +46.8773\n",
      "        15       -3330.4057         +36.2416\n",
      "        16       -3284.5816         +45.8241\n",
      "        17       -3232.0282         +52.5534\n",
      "        18       -3200.0722         +31.9560\n",
      "        19       -3178.0130         +22.0592\n",
      "        20       -3154.3021         +23.7110\n",
      "        21       -3120.7387         +33.5634\n",
      "        22       -3088.7597         +31.9790\n",
      "        23       -3065.5468         +23.2129\n",
      "        24       -3051.2371         +14.3097\n",
      "        25       -3044.6128          +6.6243\n",
      "        26       -3041.4886          +3.1242\n",
      "        27       -3039.0884          +2.4001\n",
      "        28       -3036.6782          +2.4103\n",
      "        29       -3033.9594          +2.7187\n",
      "        30       -3030.7311          +3.2283\n",
      "        31       -3026.3412          +4.3900\n",
      "        32       -3019.1792          +7.1619\n",
      "        33       -3009.3572          +9.8220\n",
      "        34       -2996.9743         +12.3829\n",
      "        35       -2978.7372         +18.2371\n",
      "        36       -2962.3487         +16.3885\n",
      "        37       -2958.5161          +3.8326\n",
      "        38       -2956.6034          +1.9126\n",
      "        39       -2955.1746          +1.4289\n",
      "        40       -2954.4343          +0.7402\n",
      "        41       -2954.0274          +0.4069\n",
      "        42       -2949.1996          +4.8278\n",
      "        43       -2925.7210         +23.4786\n",
      "        44       -2921.7040          +4.0171\n",
      "        45       -2920.7779          +0.9261\n",
      "        46       -2920.1038          +0.6741\n",
      "        47       -2919.5416          +0.5622\n",
      "        48       -2919.0650          +0.4766\n",
      "        49       -2918.6633          +0.4017\n",
      "        50       -2918.3250          +0.3383\n",
      "        51       -2918.0371          +0.2879\n",
      "        52       -2917.7877          +0.2494\n",
      "        53       -2917.5706          +0.2171\n",
      "        54       -2917.3877          +0.1829\n",
      "        55       -2917.2446          +0.1431\n",
      "        56       -2917.1421          +0.1025\n",
      "        57       -2917.0737          +0.0685\n",
      "        58       -2917.0291          +0.0446\n",
      "        59       -2916.9994          +0.0297\n",
      "        60       -2916.9783          +0.0211\n",
      "        61       -2916.9620          +0.0163\n",
      "        62       -2916.9481          +0.0139\n",
      "        63       -2916.9351          +0.0130\n",
      "        64       -2916.9222          +0.0129\n",
      "        65       -2916.9088          +0.0134\n",
      "        66       -2916.8945          +0.0143\n",
      "        67       -2916.8792          +0.0154\n",
      "        68       -2916.8626          +0.0166\n",
      "        69       -2916.8448          +0.0178\n",
      "        70       -2916.8259          +0.0188\n",
      "        71       -2916.8063          +0.0196\n",
      "        72       -2916.7862          +0.0201\n",
      "        73       -2916.7662          +0.0201\n",
      "        74       -2916.7466          +0.0196\n",
      "        75       -2916.7278          +0.0187\n",
      "        76       -2916.7103          +0.0175\n",
      "        77       -2916.6942          +0.0161\n",
      "        78       -2916.6797          +0.0145\n",
      "        79       -2916.6669          +0.0128\n",
      "        80       -2916.6557          +0.0112\n",
      "        81       -2916.6461          +0.0097\n",
      "         1       -2808.0751             +nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "nguoi\n",
      "[[0.81 0.02 0.   0.03 0.02 0.01 0.   0.1 ]\n",
      " [0.08 0.79 0.03 0.01 0.01 0.   0.   0.08]\n",
      " [0.   0.15 0.58 0.14 0.   0.03 0.08 0.01]\n",
      " [0.   0.09 0.12 0.77 0.   0.   0.02 0.  ]\n",
      " [0.06 0.   0.   0.   0.92 0.01 0.   0.01]\n",
      " [0.   0.01 0.   0.   0.03 0.95 0.01 0.  ]\n",
      " [0.03 0.   0.04 0.03 0.   0.05 0.85 0.  ]\n",
      " [0.   0.   0.16 0.   0.   0.03 0.   0.81]]\n",
      "training co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         2       -2152.9080        +655.1671\n",
      "         3       -2144.9602          +7.9478\n",
      "         4       -2132.9122         +12.0479\n",
      "         5       -2110.2039         +22.7084\n",
      "         6       -2059.9173         +50.2866\n",
      "         7       -1962.8720         +97.0453\n",
      "         8       -1854.4467        +108.4253\n",
      "         9       -1766.4346         +88.0120\n",
      "        10       -1684.5169         +81.9177\n",
      "        11       -1605.4311         +79.0858\n",
      "        12       -1532.3301         +73.1010\n",
      "        13       -1495.7027         +36.6274\n",
      "        14       -1480.2969         +15.4058\n",
      "        15       -1470.5599          +9.7370\n",
      "        16       -1462.9223          +7.6375\n",
      "        17       -1456.4436          +6.4788\n",
      "        18       -1451.0171          +5.4264\n",
      "        19       -1446.7306          +4.2865\n",
      "        20       -1443.4819          +3.2487\n",
      "        21       -1440.6288          +2.8531\n",
      "        22       -1436.9022          +3.7266\n",
      "        23       -1429.1192          +7.7830\n",
      "        24       -1423.1431          +5.9761\n",
      "        25       -1420.1670          +2.9761\n",
      "        26       -1417.7330          +2.4340\n",
      "        27       -1415.8402          +1.8927\n",
      "        28       -1414.4979          +1.3423\n",
      "        29       -1413.5904          +0.9075\n",
      "        30       -1412.9643          +0.6261\n",
      "        31       -1412.4946          +0.4697\n",
      "        32       -1412.0914          +0.4031\n",
      "        33       -1411.6928          +0.3987\n",
      "        34       -1411.2700          +0.4228\n",
      "        35       -1410.8403          +0.4298\n",
      "        36       -1410.4437          +0.3966\n",
      "        37       -1410.0974          +0.3463\n",
      "        38       -1409.7939          +0.3036\n",
      "        39       -1409.5284          +0.2654\n",
      "        40       -1409.3082          +0.2202\n",
      "        41       -1409.1402          +0.1680\n",
      "        42       -1409.0218          +0.1184\n",
      "        43       -1408.9422          +0.0796\n",
      "        44       -1408.8893          +0.0530\n",
      "        45       -1408.8530          +0.0363\n",
      "        46       -1408.8266          +0.0264\n",
      "        47       -1408.8059          +0.0207\n",
      "        48       -1408.7883          +0.0176\n",
      "        49       -1408.7723          +0.0161\n",
      "        50       -1408.7567          +0.0156\n",
      "        51       -1408.7409          +0.0158\n",
      "        52       -1408.7243          +0.0166\n",
      "        53       -1408.7065          +0.0178\n",
      "        54       -1408.6871          +0.0194\n",
      "        55       -1408.6661          +0.0210\n",
      "        56       -1408.6436          +0.0225\n",
      "        57       -1408.6201          +0.0236\n",
      "        58       -1408.5962          +0.0239\n",
      "        59       -1408.5729          +0.0233\n",
      "        60       -1408.5511          +0.0218\n",
      "        61       -1408.5315          +0.0196\n",
      "        62       -1408.5146          +0.0169\n",
      "        63       -1408.5006          +0.0141\n",
      "        64       -1408.4891          +0.0115\n",
      "        65       -1408.4799          +0.0092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "co\n",
      "[[0.72 0.   0.25 0.   0.   0.02]\n",
      " [0.   0.78 0.   0.   0.   0.22]\n",
      " [0.   0.   0.7  0.01 0.29 0.  ]\n",
      " [0.   0.16 0.   0.68 0.17 0.  ]\n",
      " [0.   0.04 0.   0.   0.54 0.41]\n",
      " [0.13 0.06 0.   0.   0.   0.81]]\n",
      "training giadinh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1       -5025.8048             +nan\n",
      "         2       -3108.0974       +1917.7074\n",
      "         3       -2537.9627        +570.1346\n",
      "         4       -2375.1237        +162.8390\n",
      "         5       -2312.6610         +62.4627\n",
      "         6       -2278.6032         +34.0578\n",
      "         7       -2249.5006         +29.1026\n",
      "         8       -2211.9150         +37.5856\n",
      "         9       -2175.5055         +36.4095\n",
      "        10       -2152.4542         +23.0513\n",
      "        11       -2136.4462         +16.0080\n",
      "        12       -2121.4395         +15.0067\n",
      "        13       -2110.1383         +11.3012\n",
      "        14       -2104.7003          +5.4380\n",
      "        15       -2101.3476          +3.3527\n",
      "        16       -2098.1567          +3.1909\n",
      "        17       -2095.5542          +2.6025\n",
      "        18       -2093.6843          +1.8699\n",
      "        19       -2092.0336          +1.6507\n",
      "        20       -2090.0161          +2.0175\n",
      "        21       -2088.1956          +1.8204\n",
      "        22       -2087.0644          +1.1312\n",
      "        23       -2086.4011          +0.6633\n",
      "        24       -2085.9526          +0.4484\n",
      "        25       -2085.6037          +0.3489\n",
      "        26       -2085.3100          +0.2937\n",
      "        27       -2085.0572          +0.2528\n",
      "        28       -2084.8447          +0.2125\n",
      "        29       -2084.6736          +0.1711\n",
      "        30       -2084.5392          +0.1345\n",
      "        31       -2084.4317          +0.1074\n",
      "        32       -2084.3426          +0.0891\n",
      "        33       -2084.2663          +0.0763\n",
      "        34       -2084.1999          +0.0665\n",
      "        35       -2084.1416          +0.0583\n",
      "        36       -2084.0903          +0.0513\n",
      "        37       -2084.0450          +0.0453\n",
      "        38       -2084.0046          +0.0404\n",
      "        39       -2083.9678          +0.0368\n",
      "        40       -2083.9327          +0.0350\n",
      "        41       -2083.8969          +0.0359\n",
      "        42       -2083.8560          +0.0409\n",
      "        43       -2083.8037          +0.0523\n",
      "        44       -2083.7309          +0.0728\n",
      "        45       -2083.6288          +0.1021\n",
      "        46       -2083.4957          +0.1331\n",
      "        47       -2083.3442          +0.1515\n",
      "        48       -2083.1950          +0.1492\n",
      "        49       -2083.0592          +0.1358\n",
      "        50       -2082.9291          +0.1301\n",
      "        51       -2082.7871          +0.1420\n",
      "        52       -2082.6228          +0.1643\n",
      "        53       -2082.4475          +0.1753\n",
      "        54       -2082.2882          +0.1593\n",
      "        55       -2082.1643          +0.1239\n",
      "        56       -2082.0768          +0.0875\n",
      "        57       -2082.0172          +0.0596\n",
      "        58       -2081.9766          +0.0406\n",
      "        59       -2081.9484          +0.0281\n",
      "        60       -2081.9285          +0.0199\n",
      "        61       -2081.9141          +0.0144\n",
      "        62       -2081.9034          +0.0107\n",
      "        63       -2081.8953          +0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "giadinh\n",
      "[[0.8  0.17 0.03 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.77 0.21 0.02 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.44 0.22 0.34 0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.87 0.03 0.1  0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.79 0.   0.21 0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.56 0.22 0.22 0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.62 0.3  0.08 0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.35 0.02 0.63 0.   0.   0.   0.\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.64 0.   0.36 0.   0.   0.\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.71 0.29 0.   0.   0.\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.3  0.7  0.   0.\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.56 0.39 0.05\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.63 0.37\n",
      "  0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.63\n",
      "  0.06 0.31 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.57 0.1  0.33 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.88 0.12 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.96 0.04]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   1.  ]]\n",
      "Testing and Labeling\n",
      "==================================\n",
      "test_giadinh\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  1.0 , true:  25 , total_word:  25\n",
      "==================================\n",
      "test_la\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.76 , true:  19 , total_word:  25\n",
      "==================================\n",
      "test_nguoi\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.84 , true:  21 , total_word:  25\n",
      "==================================\n",
      "test_cua\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  1.0 , true:  25 , total_word:  25\n",
      "==================================\n",
      "test_co\n",
      "--------------------------------------------\n",
      "!note: test_folder must contain wavs that it records exactly the word which be trained\n",
      "accuracy:  0.6 , true:  15 , total_word:  25\n",
      "Exporting models\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    class_names = [\"la\", \"cua\", \"nguoi\", \"co\", \"giadinh\", \"test_giadinh\", \"test_la\", \"test_nguoi\", \"test_cua\", \"test_co\"]\n",
    "    dataset = {}\n",
    "    train_dataset = {}\n",
    "    for cname in class_names:\n",
    "        dataset[cname] = get_class_data(os.path.join(\"train\", cname))\n",
    "        if cname[:4] != \"test\":\n",
    "#         print(f\"Load {cname} dataset to train\")\n",
    "            train_dataset[cname] = get_class_data(os.path.join(\"train\", cname))\n",
    "\n",
    "#   # Get all vectors in the datasets\n",
    "#   all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "#   print(\"vectors\", all_vectors.shape)\n",
    "#   # Run K-Means algorithm to get clusters\n",
    "#   kmeans = clustering(all_vectors)\n",
    "#   print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "\n",
    "# Get all vectors in the datasets\n",
    "    all_train_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in train_dataset.items()], axis=0)\n",
    "    print(\"vectors\", all_train_vectors.shape)\n",
    "# Run K-Means algorithm to get clusters\n",
    "    kmeans = clustering(all_train_vectors)\n",
    "    \n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "\n",
    "    models = {}\n",
    "    for cname in class_names:\n",
    "        class_vectors = dataset[cname]\n",
    "# convert all vectors to the cluster index\n",
    "# dataset['cname'] = [O^1, ... O^R]\n",
    "# O^r = (c1, c2, ... ct, ... cT)\n",
    "# O^r size T x 1\n",
    "        dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in dataset[cname]])\n",
    "\n",
    "# =================================================================\n",
    "# cua |c|~|u|~|a|\n",
    "        if cname == \"cua\":\n",
    "            print(f\"training {cname}\")\n",
    "            hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "              n_components=9, init_params='e', params='ste', verbose=True, n_iter=1000\n",
    "            ) \n",
    "            startprob_prior=np.array([0.7,0.2,0.1,0.0,0.0,0.0, 0.0,0.0]),\n",
    "            transmat_prior=np.array([                      \n",
    "                [0.2,0.5,0.2,0.1,0.0,0.0,0.0,0.0],\n",
    "                [0.0,0.2,0.5,0.2,0.1,0.0,0.0,0.0],\n",
    "                [0.0,0.0,0.2,0.5,0.2,0.1,0.0,0.0],\n",
    "                [0.0,0.0,0.0,0.2,0.5,0.2,0.1,0.0],\n",
    "                [0.0,0.0,0.0,0.0,0.2,0.5,0.2,0.1],\n",
    "                [0.0,0.0,0.0,0.0,0.0,0.2,0.6,0.2],\n",
    "                [0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.7],\n",
    "                [0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "            ]),\n",
    "            X = np.concatenate(dataset[cname])\n",
    "            lengths = list([len(x) for x in dataset[cname]])\n",
    "        #       print(\"training class\", cname)\n",
    "        #       print(X.shape, lengths, len(lengths))\n",
    "            hmm.fit(X, lengths=lengths)\n",
    "            models[cname] = hmm\n",
    "            print(\"==================================\")\n",
    "            print(cname)\n",
    "            np.set_printoptions(precision=2, suppress=True)\n",
    "            print(models[cname].transmat_)\n",
    "        # =================================================================\n",
    "#         nguoi |ng|~|uo|~|i|\n",
    "        if cname == \"nguoi\":\n",
    "            print(f\"training {cname}\")\n",
    "            hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "              n_components=8, init_params='e', params='ste', verbose=True, n_iter=1000\n",
    "            )\n",
    "            startprob_prior=np.array([0.7,0.2,0.1,0.0,0.0,0.0, 0.0,0.0]),\n",
    "            transmat_prior=np.array([                      \n",
    "                [0.2,0.5,0.2,0.1,0.0,0.0,0.0,0.0],\n",
    "                [0.0,0.2,0.5,0.2,0.1,0.0,0.0,0.0],\n",
    "                [0.0,0.0,0.2,0.5,0.2,0.1,0.0,0.0],\n",
    "                [0.0,0.0,0.0,0.2,0.5,0.2,0.1,0.0],\n",
    "                [0.0,0.0,0.0,0.0,0.2,0.5,0.2,0.1],\n",
    "                [0.0,0.0,0.0,0.0,0.0,0.2,0.6,0.2],\n",
    "                [0.0,0.0,0.0,0.0,0.0,0.0,0.3,0.7],\n",
    "                [0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "            ]),\n",
    "            X = np.concatenate(dataset[cname])\n",
    "            lengths = list([len(x) for x in dataset[cname]])\n",
    "        #       print(\"training class\", cname)\n",
    "        #       print(X.shape, lengths, len(lengths))\n",
    "            hmm.fit(X, lengths=lengths)\n",
    "            models[cname] = hmm\n",
    "            print(\"==================================\")\n",
    "            print(cname)\n",
    "            np.set_printoptions(precision=2, suppress=True)\n",
    "            print(models[cname].transmat_)\n",
    "\n",
    "        # =================================================================\n",
    "        # co |c|~|o|\n",
    "        if cname == \"co\":\n",
    "            print(f\"training {cname}\")\n",
    "            hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "              n_components=6, init_params='e', params='ste', verbose=True, n_iter=1000\n",
    "            )\n",
    "            startprob_prior=np.array([0.3,0.6,0.1,0.0,0.0,0.0])\n",
    "            transmat_prior=np.array([\n",
    "                [0.5,0.4,0.1,0.0,0.0,0.0,],\n",
    "                [0.0,0.5,0.4,0.1,0.0,0.0,],\n",
    "                [0.0,0.0,0.5,0.4,0.1,0.0,],\n",
    "                [0.0,0.0,0.0,0.5,0.4,0.1,],\n",
    "                [0.0,0.0,0.0,0.0,0.5,0.5],\n",
    "                [0.0,0.0,0.0,0.0,0.0,1.0]\n",
    "            ])\n",
    "            X = np.concatenate(dataset[cname])\n",
    "            lengths = list([len(x) for x in dataset[cname]])\n",
    "        #       print(\"training class\", cname)\n",
    "        #       print(X.shape, lengths, len(lengths))\n",
    "            hmm.fit(X, lengths=lengths)\n",
    "            models[cname] = hmm\n",
    "            print(\"==================================\")\n",
    "            print(cname)\n",
    "            np.set_printoptions(precision=2, suppress=True)\n",
    "            print(models[cname].transmat_)\n",
    "\n",
    "        # =================================================================\n",
    "        # la |l|~|a|\n",
    "        if cname == \"la\":\n",
    "            print(f\"training {cname}\")\n",
    "            hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "              n_components=6, init_params='e', params='ste', verbose=True, n_iter=1000\n",
    "            )\n",
    "            startprob_prior_=np.array([0.2,0.7,0.1,0.0,0.0,0.0])\n",
    "            transmat_prior=np.array([\n",
    "                [0.5,0.4,0.1,0.0,0.0,0.0,],\n",
    "                [0.0,0.5,0.4,0.1,0.0,0.0,],\n",
    "                [0.0,0.0,0.5,0.4,0.1,0.0,],\n",
    "                [0.0,0.0,0.0,0.5,0.4,0.1,],\n",
    "                [0.0,0.0,0.0,0.0,0.5,0.5],\n",
    "                [0.0,0.0,0.0,0.0,0.0,1.0]\n",
    "            ])\n",
    "            X = np.concatenate(dataset[cname])\n",
    "            lengths = list([len(x) for x in dataset[cname]])\n",
    "        #       print(\"training class\", cname)\n",
    "        #       print(X.shape, lengths, len(lengths))\n",
    "            hmm.fit(X, lengths=lengths)\n",
    "            models[cname] = hmm\n",
    "            print(\"==================================\")\n",
    "            print(cname)\n",
    "            np.set_printoptions(precision=2, suppress=True)\n",
    "            print(models[cname].transmat_)\n",
    "\n",
    "        # =================================================================\n",
    "        # giadinh |g|~|i|~|a|~|silent|~|d|~|i|~|nh| \n",
    "        if cname == \"giadinh\":\n",
    "            print(f\"training {cname}\")\n",
    "            hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "                n_components=18, init_params='e', params='ste', verbose=True, n_iter=1000\n",
    "            )\n",
    "            hmm.startprob_ = np.array([0.5,0.2,0.1,0.1,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "            hmm.transmat_ = np.array([\n",
    "            [0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.5],\n",
    "            [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "            ])\n",
    "            X = np.concatenate(dataset[cname])\n",
    "            lengths = list([len(x) for x in dataset[cname]])\n",
    "        #       print(\"training class\", cname)\n",
    "        #       print(X.shape, lengths, len(lengths))\n",
    "            hmm.fit(X, lengths=lengths)\n",
    "            models[cname] = hmm\n",
    "            print(\"==================================\")\n",
    "            print(cname)\n",
    "            np.set_printoptions(precision=2, suppress=True)\n",
    "            print(models[cname].transmat_)\n",
    "\n",
    "          \n",
    "    #       print(\"Training done\")\n",
    "\n",
    "    print(\"Testing and Labeling\")\n",
    "    for true_cname in class_names:\n",
    "        if true_cname[:4] == \"test\":\n",
    "            print(\"==================================\")\n",
    "            print(true_cname)\n",
    "\n",
    "            lname = true_cname[5:]\n",
    "            totalWord = 0\n",
    "            true = 0\n",
    "            accuracy = 0\n",
    "\n",
    "            for O in dataset[true_cname]:\n",
    "                totalWord += 1\n",
    "                scores = {}\n",
    "                for cname, model in models.items():\n",
    "                    if cname[:4] != \"test\":\n",
    "                        score = model.score(O, [len(O)])\n",
    "                        scores[cname] = score\n",
    "#                 print(scores)\n",
    "                srt = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "            #         print(srt[0])\n",
    "                if srt[0][0] == lname:\n",
    "                    true += 1\n",
    "            accuracy = true/totalWord\n",
    "            print(\"--------------------------------------------\")\n",
    "            print(\"!note: test_folder must contain wavs that it records exactly the word which be trained\")\n",
    "            print(\"accuracy: \", accuracy,\", true: \", true,\", total_word: \",totalWord)\n",
    "            \n",
    "    print(\"Exporting models\")\n",
    "    for label in class_names:\n",
    "        if true_cname[:4] != \"test\":\n",
    "            with open(os.path.join(\"Models\", label + \".pkl\"), \"wb\") as file: pk.dump(models[label], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
